{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to process plm1.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/plm1.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process ins9.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/ins9.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process nfle8.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/nfle8.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process nfle9.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/nfle9.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process ins1.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/ins1.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process rbd16.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/rbd16.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process sdb1.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/sdb1.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Failed to process sdb4.edf: /Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged/sdb4.edf: the file is not EDF(+) or BDF(+) compliant (Digital Minimum)\n",
      "Files that failed to process:\n",
      "plm1.edf\n",
      "ins9.edf\n",
      "nfle8.edf\n",
      "nfle9.edf\n",
      "ins1.edf\n",
      "rbd16.edf\n",
      "sdb1.edf\n",
      "sdb4.edf\n"
     ]
    }
   ],
   "source": [
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "# Define the input and output folder paths\n",
    "input_folder = \"/Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_unchanged\"\n",
    "output_folder = \"/Users/karmenmarkov/Library/CloudStorage/GoogleDrive-kkarmenmarkov@gmail.com/My Drive/masters_ppg/ppg_data_try2\"\n",
    "\n",
    "# Keep track of files that couldn't be processed\n",
    "failed_files = []\n",
    "\n",
    "# Loop through each file in the input folder\n",
    "for file_name in os.listdir(input_folder):\n",
    "    try:\n",
    "        if file_name.endswith('.edf'):\n",
    "            # Construct the input and output file paths\n",
    "            input_path = os.path.join(input_folder, file_name)\n",
    "            output_path = os.path.join(output_folder, os.path.splitext(file_name)[0] + '_ppg.csv')\n",
    "            \n",
    "            # Open the .edf file\n",
    "            with pyedflib.EdfReader(input_path) as f:\n",
    "                start_datetime = f.getStartdatetime()\n",
    "\n",
    "                # Get the PLETH signal and sampling frequency (first convert all labels to upper case)\n",
    "                upper = [element.upper() for element in f.getSignalLabels()]\n",
    "                if \"PLETH\" in upper:\n",
    "                    index = upper.index(\"PLETH\")\n",
    "                    signal = f.readSignal(index)\n",
    "                    freq = f.getSampleFrequency(index)\n",
    "                    \n",
    "                    # Create a pandas dataframe from the PLETH signal and add header information\n",
    "                    signal_pd = pd.DataFrame(signal)\n",
    "                    header = ['sampling freq (Hz):\\n'+ str(freq)+'\\n'+ 'start_datetime\\n'+ str(start_datetime)+'\\n']\n",
    "                    header_str = ','.join(header)\n",
    "                    \n",
    "                    # Write the dataframe to a CSV file with header\n",
    "                    with open(output_path, 'w') as csv_file:\n",
    "                        csv_file.write(header_str)\n",
    "                        signal_pd.to_csv(csv_file, index=None, lineterminator='\\n')\n",
    "                else:\n",
    "                    print(f\"No PLETH signal found in file: {file_name}\")\n",
    "                    failed_files.append(file_name)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process {file_name}: {e}\")\n",
    "        failed_files.append(file_name)\n",
    "\n",
    "# Print out the failed files\n",
    "print(\"Files that failed to process:\")\n",
    "for failed_file in failed_files:\n",
    "    print(failed_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
